# sentence tokenizer
import nltk
from nltk.tokenize import sent_tokenize
s= "Hello everyone. Welcome to AI."
sentences = sent_tokenize(s)
print(sentences)
